---
title: "How to out-perform default random forest regression: choosing hyperparameters for applications in large-sample hydrology"
collection: publications
permalink: /publication/HydroHyperOpt
excerpt: ''
date: 2023-05-15
venue: 'arxiv'
paperurl: 'https://arxiv.org/abs/2305.07136'
citation: 'Bilolikar, D. K., More, A., Gong, A., & Janssen, J. (2023). How to out-perform default random forest regression: choosing hyperparameters for applications in large-sample hydrology. arXiv preprint arXiv:2305.07136.'
---
Predictions are a central part of water resources research. Historically, physically-based models have been preferred; however, they have largely failed at modeling hydrological processes at a catchment scale and there are some important prediction problems that cannot be modeled physically. As such, machine learning (ML) models have been seen as a valid alternative in recent years. In spite of their availability, well-optimized state-of-the-art ML strategies are not being widely used in water resources research. This is because using state-of-the-art ML models and optimizing hyperparameters requires expert mathematical and statistical knowledge. Further, some analyses require many model trainings, so sometimes even expert statisticians cannot properly optimize hyperparameters. To leverage data and use it effectively to drive scientific advances in the field, it is essential to make ML models accessible to subject matter experts by improving automated machine learning resources. ML models such as XGBoost have been recently shown to outperform random forest (RF) models which are traditionally used in water resources research. In this study, based on over 150 water-related datasets, we extensively compare XGBoost and RF. This study provides water scientists with access to quick user-friendly RF and XGBoost model optimization.
