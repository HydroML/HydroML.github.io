---
title: "Ultra-marginal Feature Importance: Learning from Data with Causal Guarantees"
collection: publications
permalink: /publication/UMFI2023
excerpt: ''
date: 2023-04-22
venue: 'AISTATS'
paperurl: 'https://arxiv.org/abs/2204.09938'
citation: 'Janssen, J., Guan, V., & Robeva, E. (2023, April). Ultra-marginal Feature Importance: Learning from Data with Causal Guarantees. In International Conference on Artificial Intelligence and Statistics (pp. 10782-10814). PMLR.'
---
Scientists frequently prioritize learning from data rather than training the best possible model; however, research in machine learning often prioritizes the latter. Marginal contribution feature importance (MCI) was developed to break this trend by providing a useful framework for quantifying the relationships in data. In this work, we aim to improve upon the theoretical properties, performance, and runtime of MCI by introducing ultra-marginal feature importance (UMFI), which uses dependence removal techniques from the AI fairness literature as its foundation. We first propose axioms for feature importance methods that seek to explain the causal and associative relationships in data, and we prove that UMFI satisfies these axioms under basic assumptions. We then show on real and simulated data that UMFI performs better than MCI, especially in the presence of correlated interactions and unrelated features, while partially learning the structure of the causal graph and reducing the exponential runtime of MCI to super-linear.
